{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning from scratch with Pytorch\n",
    "**A Pytorch implementation of the Federated Learning Algorithm FedAvg on MNIST dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Federated Learning is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. Federated Learning represents a possible solution to the problem of data privacy and data security in machine learning.\n",
    "\n",
    "In this project I implemented the Federated Learning algorithm **FedAvg** formulated by McMahan, et al. [1] which is a first approach to this challange.\n",
    "\n",
    "<img src=\"images/algo.png\" alt=\"Image Description\" width=\"400\" height=\"400\">\n",
    "\n",
    "Basically the algorithm is divided into two phases: the **Client Update** and the **Server Update**. In the **Client Update** phase, each client trains its local model on its local sample of data for the number of local epochs, using the local batch size. In the **Server Update** phase, the server averages the models weights of all the clients to create a new global model. This global model is then sent to all the clients to start a new round of training. In this way, the server never has access to the raw data but only to the model weights, and the global model is a good approximation of the model that would have been obtained by training on the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "I implemented the algorithm using Pytorch and I tested it on the MNIST dataset for semplicity. \n",
    "\n",
    "The project is divided into the following files:\n",
    "- `fedsgd.py`: the main file that contains the implementation of the FedAvg algorithm\n",
    "- `Client.py`: the file that contains the implementation of the `Client` class\n",
    "- `Server.py`: the file that contains the implementation of the `Server` class\n",
    "- `models.py`: the file that contains the implementation of the neural models\n",
    "\n",
    "### Client\n",
    "The `Client.py` file contains the implementation of the client class. Each client has its own dataloader, model and optimizer, the learning rate and the number of local epochs can be set by the user. The method `train` implements the **Client Update** phase.\n",
    "\n",
    "```python\n",
    "def train(self, num_epochs, patience, params, progress_bar):\n",
    "        self.model.load_state_dict(params)\n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for batch_idx, (x, y) in enumerate(self.data):\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                y_pred = self.model(x)\n",
    "                loss = self.loss_func(y_pred, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.set_postfix({\"loss\": running_loss / len(self.data)})\n",
    "        return running_loss / len(self.data)\n",
    "```\n",
    "\n",
    "### Server\n",
    "The `Server.py` file contains the implementation of the server class. The server has a model and a list of clients, it also has the method `aggregate` that implements the **Server Update** phase. Notice that the function does not return the new global model but it updates the model inplace.\n",
    "\n",
    "```python\n",
    "def aggregate(self):\n",
    "\t\tparams = [client.get_params() for client in self.clients]\n",
    "        avg_params = {}\n",
    "        for key in params[0].keys():\n",
    "            avg_params[key] = torch.stack(\n",
    "                [params[i][key] for i in range(len(params))], 0\n",
    "            ).mean(0)\n",
    "        self.model.load_state_dict(avg_params)\n",
    "```\n",
    "\n",
    "### Algorithm Loop\n",
    "Finally the `fedsgd.py` file contains the main function that runs the algorithm. The function `fedSgdSeq` runs the sequential version of the algorithm, while the function `fedSgdPar` runs the parallel version of the algorithm. The algorithm run for `T` rounds, first the server get the current global model state and then sends it to all the clients. Next the clients train their local model, which they updated to the new one, moving into their local optimizer direction for local epochs step and then they send the model back to the server. The server aggregates the models and sends the new global model to all the clients. At the end of the training the server evaluates the model on the test set.\n",
    "\n",
    "```python\n",
    "def fedSgdSeq(\n",
    "    model=Cnn(),\n",
    "    T=5,                # number of rounds\n",
    "    K=10,               # number of clients\n",
    "    C=1,                # fraction of clients\n",
    "    E=10,               # number of local epochs\n",
    "    B=128,              # local batch size\n",
    "    num_samples=1000,   # number of training samples on each client\n",
    "    lr=0.01,            # learning rate\n",
    "    weight_decay=10e-6, # weight decay\n",
    "    patience=5,         # patience for early stopping\n",
    "):\n",
    "    # ... code ...\n",
    "    clients = []\n",
    "    for i in range(num_clients):\n",
    "        client = Client(\n",
    "            i,\n",
    "            trainloader[i],\n",
    "            Cnn() if model.get_type() == \"Cnn\" else Net(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            device=device,\n",
    "        )\n",
    "        clients.append(client)\n",
    "    # ... code ...\n",
    "    # FedAvg algorithm sequential version\n",
    "    for r in range(T):\n",
    "            params = server.get_params()\n",
    "            progress_bar = tqdm.tqdm(\n",
    "                total=E * num_clients, position=0, leave=False, desc=\"Round %d\" % r\n",
    "            )\n",
    "            for client in clients:\n",
    "                loss = client.train(E, patience, params, progress_bar)\n",
    "            server.aggregate()\n",
    "            val_loss, val_acc = server.test(valoader)\n",
    "            print(\"Server - Val loss: %.3f, Val accuracy: %.3f\" % (val_loss, val_acc))\n",
    "        test_loss, test_acc = server.test(testloader)\n",
    "```\n",
    "\n",
    "The dataset is splitted into training, validation and test set. The training set is divided into `K` clients, each client has a dataloader that samples `num_samples` samples from the training set. The validation set is used to evaluate the model at the end of each round, while the test set is used to evaluate the model at the end of the training. \n",
    "\n",
    "The parallel version uses the `joblilb` module to create a thread for each client, in this way we simulate better the real scenario where the clients are distributed on different devices.\n",
    "\n",
    "```python\n",
    "for r in range(T):\n",
    "    params = server.get_params()\n",
    "    progress_bar = tqdm.tqdm(\n",
    "        total=E * num_clients, position=0, leave=False, desc=\"Round %d\" % r\n",
    "    )\n",
    "    joblib.Parallel(n_jobs=num_clients, backend=\"threading\")(\n",
    "        joblib.delayed(client.train)(E, patience, params, progress_bar)\n",
    "        for client in clients\n",
    "    )\n",
    "    server.aggregate()\n",
    "    val_loss, val_acc = server.test(valoader)\n",
    "    print(\"Server - Val loss: %.3f, Val accuracy: %.3f\" % (val_loss, val_acc))\n",
    "test_loss, test_acc = server.test(testloader)\n",
    "```\n",
    "\n",
    "This implemenation allows to test different configurations of the algorithm. In particular if we set `C = 1`, `E = 1` and `B = inf` we obtain the **FedSGD** algorithm, which is the baseline algorithm for the Federated Learning presented in the paper [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Parallel implementation FedSGD on MNIST dataset\n",
      "- Parameters: T=20, K=10, C=1, E=10, B=128, num_samples=1000, lr=0.01, weight_decay=0.0001, patience=5\n",
      "- Model: Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 0: 100%|██████████| 100/100 [00:20<00:00, 11.57it/s, loss=2.05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 2.035, Val accuracy: 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 1: 100%|██████████| 100/100 [00:19<00:00,  6.90it/s, loss=1.46]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 1.420, Val accuracy: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 2: 100%|██████████| 100/100 [00:19<00:00, 10.66it/s, loss=0.896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.891, Val accuracy: 0.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 3: 100%|██████████| 100/100 [00:19<00:00,  6.64it/s, loss=0.603]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.661, Val accuracy: 0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 4: 100%|██████████| 100/100 [00:19<00:00,  5.73it/s, loss=0.538]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.551, Val accuracy: 0.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 5: 100%|██████████| 100/100 [00:19<00:00,  7.39it/s, loss=0.443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.489, Val accuracy: 0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 6: 100%|██████████| 100/100 [00:19<00:00,  9.69it/s, loss=0.391]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.450, Val accuracy: 0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 7: 100%|██████████| 100/100 [00:19<00:00,  8.19it/s, loss=0.36] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.422, Val accuracy: 0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 8: 100%|██████████| 100/100 [00:19<00:00, 15.63it/s, loss=0.334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.402, Val accuracy: 0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 9: 100%|██████████| 100/100 [00:19<00:00,  6.91it/s, loss=0.352]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.387, Val accuracy: 0.890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 10: 100%|██████████| 100/100 [00:19<00:00, 10.19it/s, loss=0.346]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.375, Val accuracy: 0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 11: 100%|██████████| 100/100 [00:19<00:00,  7.30it/s, loss=0.327]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.364, Val accuracy: 0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 12: 100%|██████████| 100/100 [00:19<00:00,  9.04it/s, loss=0.271]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.356, Val accuracy: 0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 13: 100%|██████████| 100/100 [00:19<00:00,  4.87it/s, loss=0.258]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.349, Val accuracy: 0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 14: 100%|██████████| 100/100 [00:19<00:00,  8.72it/s, loss=0.293]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.342, Val accuracy: 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 15: 100%|██████████| 100/100 [00:18<00:00,  7.27it/s, loss=0.26] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.336, Val accuracy: 0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 16: 100%|██████████| 100/100 [00:19<00:00,  9.66it/s, loss=0.281]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.330, Val accuracy: 0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 17: 100%|██████████| 100/100 [00:20<00:00,  9.81it/s, loss=0.242]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.326, Val accuracy: 0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 18: 100%|██████████| 100/100 [00:20<00:00,  7.91it/s, loss=0.259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.322, Val accuracy: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 19: 100%|██████████| 100/100 [00:20<00:00,  4.73it/s, loss=0.2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server - Val loss: 0.317, Val accuracy: 0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "-- Test loss: 0.285, Test accuracy: 0.917 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from src.fedsgd import fedSgdPar, fedSgdSeq\n",
    "from src.models import Net, Cnn\n",
    "\n",
    "fedSgdPar(model=Net(), T=20, K=10, C=1, E=10, B=128, num_samples=1000, lr=0.01, weight_decay=10e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] [H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, Communication-Efficient Learning of Deep Networks from Decentralized Data. 2023.](https://arxiv.org/abs/1602.05629)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "- [x] Add implementation code description: \n",
    "\t- [x] `Client` class\n",
    "\t- [x] `Server` class\n",
    "\t- [x] `models` class\n",
    "\t- [x] `fedSgdPar` and `fedSgd` algorithm (show the algorithm code)\n",
    "- [ ] Add early stopping to server and client (?)\n",
    "- [ ] Run experiment (from the paper)\n",
    "- [ ] Show results\n",
    "- [x] Code refactoring: move the class in separate files and the main code in a separate file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
